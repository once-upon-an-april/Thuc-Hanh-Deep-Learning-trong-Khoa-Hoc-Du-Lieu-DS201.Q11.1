{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "17jxpTD828IpjNvaagzqwNVgZtn59_YLw",
      "authorship_tag": "ABX9TyOx2KDoHxJWe/xCv6OBSrcl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/once-upon-an-april/Thuc-Hanh-Deep-Learning-trong-Khoa-Hoc-Du-Lieu-DS201.Q11.1/blob/main/Bai3/22520975_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHUẨN BỊ MÔI TRƯỜNG"
      ],
      "metadata": {
        "id": "KpA6SPgeyvQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets pyvi torchmetrics"
      ],
      "metadata": {
        "id": "UaEhb_Zby7CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from datasets import load_dataset\n",
        "from pyvi import ViTokenizer\n",
        "from torchmetrics.text.rouge import ROUGEScore\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "import time"
      ],
      "metadata": {
        "id": "Mrr0w6HzzQm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device đang sử dụng: {device}\")"
      ],
      "metadata": {
        "id": "auNOd-n90PHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TIỀN XỬ LÝ DỮ LIỆU"
      ],
      "metadata": {
        "id": "rMYXF_rI1BTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LEN = 100\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, dataset_iterator, key, is_src=True, max_size=20000, min_freq=3):\n",
        "        self.token2idx = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "        self.idx2token = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.is_src = is_src\n",
        "\n",
        "        print(f\"Đang xây dựng từ điển ({'Tiếng Anh' if is_src else 'Tiếng Việt'})...\")\n",
        "        counter = Counter()\n",
        "        for item in dataset_iterator:\n",
        "            text = item[key]\n",
        "            tokens = self.tokenize(text)\n",
        "            counter.update(tokens)\n",
        "\n",
        "        most_common = [token for token, freq in counter.most_common(max_size) if freq >= min_freq]\n",
        "        for idx, token in enumerate(most_common, start=4):\n",
        "            self.token2idx[token] = idx\n",
        "            self.idx2token[idx] = token\n",
        "\n",
        "        print(f\"-> Hoàn tất. Kích thước Vocab: {len(self.token2idx)}\")\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        text = str(text).lower().strip()\n",
        "        if not self.is_src:\n",
        "            return ViTokenizer.tokenize(text).split()\n",
        "        return text.split()\n",
        "\n",
        "    def encode(self, text, max_len=None):\n",
        "        tokens = self.tokenize(text)\n",
        "        # TRUNCATION: Cắt ngắn nếu quá dài\n",
        "        if max_len is not None and len(tokens) > max_len - 2: # -2 cho SOS và EOS\n",
        "            tokens = tokens[:max_len-2]\n",
        "\n",
        "        return [1] + [self.token2idx.get(t, 3) for t in tokens] + [2]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        tokens = []\n",
        "        for idx in indices:\n",
        "            if isinstance(idx, torch.Tensor): idx = idx.item()\n",
        "            if idx == 2: break\n",
        "            if idx in [0, 1, 3]: continue\n",
        "            tokens.append(self.idx2token.get(idx, \"<UNK>\"))\n",
        "        return \" \".join(tokens).replace(\"_\", \" \")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token2idx)\n",
        "\n",
        "class PhoMTDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, src_vocab=None, tgt_vocab=None):\n",
        "        self.data = hf_dataset\n",
        "        self.src_key = 'en' if 'en' in self.data.column_names else 'src'\n",
        "        self.tgt_key = 'vi' if 'vi' in self.data.column_names else 'tgt'\n",
        "\n",
        "        if src_vocab is None:\n",
        "            self.src_vocab = Vocab(self.data, self.src_key, is_src=True)\n",
        "            self.tgt_vocab = Vocab(self.data, self.tgt_key, is_src=False)\n",
        "        else:\n",
        "            self.src_vocab = src_vocab\n",
        "            self.tgt_vocab = tgt_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        src_text = item[self.src_key]\n",
        "        tgt_text = item[self.tgt_key]\n",
        "        # ÁP DỤNG MAX LENGTH TẠI ĐÂY\n",
        "        src_encoded = self.src_vocab.encode(src_text, max_len=MAX_SEQ_LEN)\n",
        "        tgt_encoded = self.tgt_vocab.encode(tgt_text, max_len=MAX_SEQ_LEN)\n",
        "        return torch.tensor(src_encoded), torch.tensor(tgt_encoded)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_pad = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
        "    tgt_pad = pad_sequence(tgt_batch, padding_value=0, batch_first=True)\n",
        "    return src_pad, tgt_pad"
      ],
      "metadata": {
        "id": "ZQNTVNQP1FXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Đang tải dataset ura-hcmut/PhoMT từ Hugging Face...\")\n",
        "dataset = load_dataset(\"ura-hcmut/PhoMT\", \"default\")"
      ],
      "metadata": {
        "id": "wDK_HLsO4R4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_full = dataset['train']\n",
        "valid_data_full = dataset['validation']"
      ],
      "metadata": {
        "id": "ZXKZ8OEb6hbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Số lượng mẫu Train: {len(train_data_full)}\")\n",
        "print(f\"Số lượng mẫu Validation: {len(valid_data_full)}\")"
      ],
      "metadata": {
        "id": "atFo97Jc56HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Đang xử lý dữ liệu...\")\n",
        "\n",
        "train_dataset = PhoMTDataset(train_data_full)\n",
        "valid_dataset = PhoMTDataset(valid_data_full, src_vocab=train_dataset.src_vocab, tgt_vocab=train_dataset.tgt_vocab)"
      ],
      "metadata": {
        "id": "Kho6Gqq06rq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)"
      ],
      "metadata": {
        "id": "7A0ddgwZ60aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "m0VyYu8E_DXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=3, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "class DecoderBasic(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=3, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, input_token, hidden, cell, encoder_outputs=None):\n",
        "        embedded = self.dropout(self.embedding(input_token))\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(1))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query.unsqueeze(1)) + self.Ua(keys)))\n",
        "        weights = torch.softmax(scores, dim=1)\n",
        "        context = torch.bmm(weights.transpose(1, 2), keys)\n",
        "        return context, weights\n",
        "\n",
        "class DecoderBahdanau(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=3, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embedding_dim + hidden_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
        "        embedded = self.dropout(self.embedding(input_token))\n",
        "        query = hidden[-1]\n",
        "        context, _ = self.attention(query, encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded, context), dim=2)\n",
        "        output, (hidden, cell) = self.lstm(rnn_input, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(1))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        keys_proj = self.W(keys)\n",
        "        scores = torch.bmm(query, keys_proj.transpose(1, 2))\n",
        "        weights = torch.softmax(scores, dim=2)\n",
        "        context = torch.bmm(weights, keys)\n",
        "        return context, weights\n",
        "\n",
        "class DecoderLuong(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=3, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.attention = LuongAttention(hidden_size)\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc_concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
        "        embedded = self.dropout(self.embedding(input_token))\n",
        "        lstm_out, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        context, _ = self.attention(lstm_out, encoder_outputs)\n",
        "        concat_input = torch.cat((lstm_out, context), dim=2)\n",
        "        concat_output = torch.tanh(self.fc_concat(concat_input))\n",
        "        prediction = self.fc_out(concat_output.squeeze(1))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.shape[0]\n",
        "        tgt_len = tgt.shape[1]\n",
        "        vocab_size = self.decoder.fc_out.out_features\n",
        "        outputs = torch.zeros(batch_size, tgt_len, vocab_size).to(self.device)\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "        input_token = tgt[:, 0].unsqueeze(1)\n",
        "\n",
        "        for t in range(1, tgt_len):\n",
        "            if isinstance(self.decoder, DecoderBasic):\n",
        "                prediction, hidden, cell = self.decoder(input_token, hidden, cell)\n",
        "            else:\n",
        "                prediction, hidden, cell = self.decoder(input_token, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t] = prediction\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top_token = prediction.argmax(1).unsqueeze(1)\n",
        "            input_token = tgt[:, t].unsqueeze(1) if teacher_force else top_token\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "tOsyCj3U_FNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ],
      "metadata": {
        "id": "vQZur-XI_f5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    # Clean memory trước khi train\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    for i, (src, tgt) in enumerate(iterator):\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "        tgt = tgt[:, 1:].reshape(-1)\n",
        "        loss = criterion(output, tgt)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Step {i}/{len(iterator)} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate_rouge(model, iterator, vocab_tgt):\n",
        "    model.eval()\n",
        "    rouge = ROUGEScore()\n",
        "    preds_text = []\n",
        "    targets_text = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (src, tgt) in enumerate(iterator):\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "            output = model(src, tgt, teacher_forcing_ratio=0)\n",
        "            output_indices = output.argmax(2).tolist()\n",
        "            tgt_indices = tgt.tolist()\n",
        "            for j in range(len(output_indices)):\n",
        "                p = vocab_tgt.decode(output_indices[j])\n",
        "                t = vocab_tgt.decode(tgt_indices[j])\n",
        "                preds_text.append(p)\n",
        "                targets_text.append(t)\n",
        "            if i > 50: break # Chỉ eval mẫu để tránh mất thời gian\n",
        "\n",
        "    scores = rouge(preds_text, targets_text)\n",
        "    return scores['rougeL_fmeasure'].item()\n",
        "\n",
        "def run_experiment(task_name):\n",
        "    # Cấu hình\n",
        "    ENC_EMB = 256\n",
        "    DEC_EMB = 256\n",
        "    HID_DIM = 256\n",
        "    N_LAYERS = 3\n",
        "    ENC_DROP = 0.5\n",
        "    DEC_DROP = 0.5\n",
        "    LR = 0.001\n",
        "    N_EPOCHS = 1 # Dù để 1 epoch nhưng nếu lâu quá bạn cứ bấm Stop\n",
        "\n",
        "    INPUT_DIM = len(train_dataset.src_vocab)\n",
        "    OUTPUT_DIM = len(train_dataset.tgt_vocab)\n",
        "\n",
        "    # Dọn dẹp bộ nhớ\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"\\n{'='*20}\\nBẮT ĐẦU: {task_name}\\n{'='*20}\")\n",
        "\n",
        "    # Khởi tạo model\n",
        "    enc = Encoder(INPUT_DIM, ENC_EMB, HID_DIM, N_LAYERS, ENC_DROP)\n",
        "\n",
        "    if task_name == 'Bai 1 (Basic)':\n",
        "        dec = DecoderBasic(OUTPUT_DIM, DEC_EMB, HID_DIM, N_LAYERS, DEC_DROP)\n",
        "    elif task_name == 'Bai 2 (Bahdanau)':\n",
        "        dec = DecoderBahdanau(OUTPUT_DIM, DEC_EMB, HID_DIM, N_LAYERS, DEC_DROP)\n",
        "    elif task_name == 'Bai 3 (Luong)':\n",
        "        dec = DecoderLuong(OUTPUT_DIM, DEC_EMB, HID_DIM, N_LAYERS, DEC_DROP)\n",
        "\n",
        "    model = Seq2Seq(enc, dec, device).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "    # --- KHỐI LỆNH TRY-EXCEPT ĐỂ BẮT SỰ KIỆN DỪNG ---\n",
        "    try:\n",
        "        for epoch in range(N_EPOCHS):\n",
        "            start_time = time.time()\n",
        "            print(f\"Epoch {epoch+1} đang chạy... (Bấm Stop để dừng sớm và giữ model)\")\n",
        "\n",
        "            # Train loop\n",
        "            train_loss = train_epoch(model, train_loader, optimizer, criterion, 1)\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f'Epoch: {epoch+1:02} | Time: {end_time - start_time:.0f}s | Train Loss: {train_loss:.3f}')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\n>>> ĐÃ DỪNG THỦ CÔNG! (Bạn đã bấm nút Stop)\")\n",
        "        print(\">>> Đang lưu lại trạng thái Model hiện tại để đánh giá...\")\n",
        "\n",
        "    # Đánh giá model\n",
        "    print(\"\\nĐang đánh giá ROUGE-L trên tập Validation...\")\n",
        "    rouge_l = evaluate_rouge(model, valid_loader, train_dataset.tgt_vocab)\n",
        "    print(f'>> KẾT QUẢ CUỐI CÙNG {task_name} - ROUGE-L: {rouge_l:.4f}')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "a7DlsPbY_h-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN EXECUTION"
      ],
      "metadata": {
        "id": "Mmn7xXnz_mMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "run_experiment('Bai 1 (Basic)')"
      ],
      "metadata": {
        "id": "iIY__CRw_2vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment('Bai 2 (Bahdanau)')"
      ],
      "metadata": {
        "id": "uprD28bwBKmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_experiment('Bai 3 (Luong)')"
      ],
      "metadata": {
        "id": "k81i8hwFBMP3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}