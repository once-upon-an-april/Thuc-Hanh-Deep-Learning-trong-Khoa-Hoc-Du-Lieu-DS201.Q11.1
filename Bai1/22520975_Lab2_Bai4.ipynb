{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "13pid0MK6DkVJ0fXRokYPgBb12EojBx8o",
      "authorship_tag": "ABX9TyMls7zWh2m8OPerUTMYBilq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/once-upon-an-april/Thuc-Hanh-Deep-Learning-trong-Khoa-Hoc-Du-Lieu-DS201.Q11.1/blob/main/Bai1/22520975_Lab2_Bai4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "HXW4Fsdh3_V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "tDjCD1584ucZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cấu hình chung ---\n",
        "DATA_DIR = '/content/drive/MyDrive/Data/VinaFood21/VinaFood21'\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Sử dụng thiết bị: {device}\")\n",
        "\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print(f\"LỖI: Không tìm thấy thư mục '{DATA_DIR}'.\")\n",
        "    print(\"Vui lòng kiểm tra lại đường dẫn Google Drive của bạn.\")\n",
        "\n",
        "NUM_CLASSES = 21 # VinaFood21"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcOXjjr95G84",
        "outputId": "45758c96-4c12-4f4d-ff0a-84c63df753c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sử dụng thiết bị: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloaders(img_size, batch_size=32):\n",
        "    \"\"\"Tải dữ liệu với kích thước ảnh cụ thể.\"\"\"\n",
        "    print(f\"\\nĐang tải dữ liệu với kích thước {img_size}x{img_size}...\")\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "    try:\n",
        "        image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])\n",
        "                          for x in ['train', 'test']}\n",
        "        dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=(x=='train'), num_workers=2)\n",
        "                       for x in ['train', 'test']}\n",
        "        dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
        "        class_names = image_datasets['train'].classes\n",
        "        print(f\"Tải xong. {dataset_sizes['train']} ảnh train, {dataset_sizes['test']} ảnh test.\")\n",
        "        return dataloaders, dataset_sizes, class_names\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Lỗi: Không tìm thấy thư mục 'train' hoặc 'test' trong {DATA_DIR}\")\n",
        "        return None, None, None"
      ],
      "metadata": {
        "id": "WlCDDrId_jqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_evaluate(model, dataloader):\n",
        "    \"\"\"Hàm đánh giá nhanh (chỉ tính Acc) để xem sau mỗi epoch.\"\"\"\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            total += labels.size(0)\n",
        "    acc = running_corrects.double() / total\n",
        "    print(f'Test Acc (Validation): {acc:.4f}')\n",
        "    model.train() # Chuyển lại chế độ train"
      ],
      "metadata": {
        "id": "l6yk2PMvAO3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_torchvision(model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs):\n",
        "    \"\"\"Hàm huấn luyện cho LeNet và ResNet (output chuẩn).\"\"\"\n",
        "    since = time.time()\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        model.train() # Đặt mô hình ở chế độ training\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in tqdm(dataloaders['train'], desc=f\"Training Epoch {epoch+1}\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes['train']\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
        "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        # Đánh giá nhanh trên tập test (validation) sau mỗi epoch\n",
        "        quick_evaluate(model, dataloaders['test'])\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'\\nHuấn luyện hoàn tất trong {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    return model"
      ],
      "metadata": {
        "id": "tKMPjw1q_tsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_googlenet(model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs):\n",
        "    \"\"\"Hàm huấn luyện đặc biệt cho GoogLeNet (có 3 output).\"\"\"\n",
        "    since = time.time()\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        model.train() # Đặt mô hình ở chế độ training\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in tqdm(dataloaders['train'], desc=f\"Training Epoch {epoch+1}\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                main_out, aux1_out, aux2_out = model(inputs)\n",
        "                loss_main = criterion(main_out, labels)\n",
        "                loss_aux1 = criterion(aux1_out, labels)\n",
        "                loss_aux2 = criterion(aux2_out, labels)\n",
        "                loss = loss_main + 0.3 * (loss_aux1 + loss_aux2)\n",
        "                _, preds = torch.max(main_out, 1)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes['train']\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
        "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        # Đánh giá nhanh trên tập test (validation) sau mỗi epoch\n",
        "        quick_evaluate(model, dataloaders['test'])\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'\\nHuấn luyện hoàn tất trong {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    return model"
      ],
      "metadata": {
        "id": "4ZL_CzZs_6YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_metrics(model, dataloader):\n",
        "    \"\"\"Đánh giá mô hình trên tập test và tính Precision, Recall, F1-macro.\"\"\"\n",
        "    print(\"\\nĐang đánh giá chi tiết trên tập Test...\")\n",
        "    model = model.to(device)\n",
        "    model.eval() # Chuyển sang chế độ eval\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_labels,\n",
        "        all_preds,\n",
        "        average='macro',\n",
        "        zero_division=0\n",
        "    )\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    print(\"\\n--- KẾT QUẢ ĐÁNH GIÁ (Macro Average) ---\")\n",
        "    print(f'Accuracy:  {accuracy:.4f}')\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall:    {recall:.4f}')\n",
        "    print(f'F1-Score:  {f1:.4f}')\n",
        "    print(\"-\" * 39)"
      ],
      "metadata": {
        "id": "sUZs6nEqASxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Tải Dữ Liệu ---\n",
        "dataloaders_28, sizes_28, classes_28 = get_dataloaders(img_size=28, batch_size=64)\n",
        "dataloaders_224, sizes_224, classes_224 = get_dataloaders(img_size=224, batch_size=32)"
      ],
      "metadata": {
        "id": "pFjgY76xAWxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d436368d-1eea-4709-9979-823741043b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Đang tải dữ liệu với kích thước 28x28...\n",
            "Tải xong. 10089 ảnh train, 6693 ảnh test.\n",
            "\n",
            "Đang tải dữ liệu với kích thước 224x224...\n",
            "Tải xong. 10089 ảnh train, 6693 ảnh test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "SG3gR6AtKKkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------\n",
        "# BÀI 4: ResNet-50 (HuggingFace)\n",
        "# -------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BẮT ĐẦU BÀI 4: ResNet-50 (HuggingFace)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "from huggingface_hub import HfFolder, login\n",
        "\n",
        "if os.path.exists(os.path.join(DATA_DIR, 'train')):\n",
        "    # 1. Tải dataset\n",
        "    print(\"Đang tải VinaFood21 bằng HuggingFace datasets...\")\n",
        "    dataset = load_dataset(\"imagefolder\", data_dir=DATA_DIR)\n",
        "\n",
        "    # 2. Lấy nhãn\n",
        "    labels = dataset[\"train\"].features[\"label\"].names\n",
        "    label2id, id2label = {}, {}\n",
        "    for i, label in enumerate(labels):\n",
        "        label2id[label] = str(i)\n",
        "        id2label[str(i)] = label\n",
        "    print(f\"Phát hiện {len(labels)} lớp.\")\n",
        "\n",
        "    # 3. Tải Image Processor\n",
        "    model_checkpoint = \"microsoft/resnet-50\"\n",
        "    processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "\n",
        "    # 4. Hàm transform\n",
        "    def transform_hf(examples):\n",
        "        inputs = processor(examples[\"image\"], return_tensors=\"pt\")\n",
        "        inputs[\"label\"] = examples[\"label\"]\n",
        "        return inputs\n",
        "    dataset = dataset.with_transform(transform_hf)\n",
        "\n",
        "    # 5. Data collator\n",
        "    def collate_fn(examples):\n",
        "        pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "        labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "        return {\"pixel_values\": pixel_values, \"label\": labels}\n",
        "\n",
        "    # 6. Tải mô hình\n",
        "    print(\"Đang tải mô hình ResNet-50 từ HuggingFace...\")\n",
        "    model_hf = AutoModelForImageClassification.from_pretrained(\n",
        "        model_checkpoint,\n",
        "        num_labels=NUM_CLASSES,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "\n",
        "    # 7. Hàm tính metrics\n",
        "    def compute_metrics_hf(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='macro', zero_division=0)\n",
        "        acc = accuracy_score(labels, predictions)\n",
        "        return {'accuracy': acc, 'precision_macro': precision, 'recall_macro': recall, 'f1_macro': f1}\n",
        "\n",
        "    # 8. Training Arguments\n",
        "    NUM_EPOCHS_B4 = 10 # Số epochs hợp lý cho Fine-tuning\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./vinafood_resnet50_hf\",\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=32,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        num_train_epochs=NUM_EPOCHS_B4,\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        logging_steps=100,\n",
        "        optim=\"adamw_torch\", # Sử dụng AdamW (biến thể của Adam)\n",
        "        learning_rate=2e-5,\n",
        "        remove_unused_columns=False,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    # 9. Khởi tạo Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model_hf,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset[\"train\"],\n",
        "        eval_dataset=dataset[\"test\"],\n",
        "        tokenizer=processor,\n",
        "        compute_metrics=compute_metrics_hf,\n",
        "        data_collator=collate_fn,\n",
        "    )\n",
        "\n",
        "    # 10. Huấn luyện\n",
        "    print(f\"\\nHuấn luyện ResNet-50 (HuggingFace) trong {NUM_EPOCHS_B4} epochs...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # 11. Đánh giá\n",
        "    print(\"\\n[Bài 4: ResNet-50] Đánh giá cuối cùng:\")\n",
        "    eval_results = trainer.evaluate(dataset[\"test\"])\n",
        "\n",
        "    print(\"\\n--- KẾT QUẢ ĐÁNH GIÁ (HuggingFace) ---\")\n",
        "    print(f\"Accuracy:  {eval_results['eval_accuracy']:.4f}\")\n",
        "    print(f\"Precision: {eval_results['eval_precision_macro']:.4f}\")\n",
        "    print(f\"Recall:    {eval_results['eval_recall_macro']:.4f}\")\n",
        "    print(f\"F1-Score:  {eval_results['eval_f1_macro']:.4f}\")\n",
        "    print(\"-\" * 39)\n",
        "\n",
        "else:\n",
        "    print(\"Bỏ qua Bài 4 do không tải được dữ liệu.\")"
      ],
      "metadata": {
        "id": "WXVu3BcQAprc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}